---
title: "Movie Recommendation Project"
author: "Jake Hogan"
date: "11/13/2020"
output: 
  pdf_document:
    fig_caption: yes
header-includes:
  \usepackage{float}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.pos = "H", fig.align = "center")
```
# Executive Summary
\
Recommendation systems are a common application of machine learning throughout the tech industry from recommending products on Amazon to recommending movies on Netflix. The goal of this project was to create a movie recommendation system based on the MovieLens dataset that minimizes the residual mean squared error (RMSE).  The dataset used for this analysis is a smaller subset of the one generated by the GroupLens research lab and contains 10 million movie ratings of 10,000 movies by 72,000 users. Data analysis and visualization was used to determine the effects that the movie, user, genre, and age of the movie have on the rating.  Then a linear regression model was created to account for each of these effects and predict movie ratings.  The recommendation model was tested once on a validation dataset with a final RMSE of 0.8623.

# Data Analysis

The 10 million rating MovieLens dataset can be found on the GroupLens Website [(grouplens.org)](https://grouplens.org/datasets/movielens/10m/).  The data comes in two files, a ratings file and a movies file. The entries in each file are delimited by "::" which is used to define a new column in the file.  The ratings dataset is assigned the column names userId, movieId, rating, and timestamp.  The movies dataset is assigned the column names movieId, title, and genres. A single movielens data frame is created by joining the ratings and movies datasets by the movieId.  From there the MovieLens data is partitioned into two data frames. The first is the validation set which is 10% of the MovieLens data and the rest goes into the edx set.  The validation set will only be used once to validate the model that is created using only the edx set.  

```{r download and organize data, echo = FALSE, message = FALSE, warning = FALSE}

##########################################################
# Create edx set, validation set (final hold-out test set)
##########################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(kableExtra)) install.packages("kableExtra", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(data.table)

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

#substite "::" for tab in ratings set
ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

#split the movies file into 3 cols using "::" as the splitter
movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

# if using R 4.0 or later:
#create movies df and join with ratings 
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           title = as.character(title),
                                           genres = as.character(genres))


movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.5 or earlier, use `set.seed(1)`
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)
#delete temp files used to create edx and validation sets
rm(dl, ratings, movies, test_index, temp, movielens, removed)

```

Looking into the edx data set shows that it has `r nrow(edx)` rows and `r ncol(edx)` columns. This breaks down to `r n_distinct(edx$movieId)` different movies and `r n_distinct(edx$userId)` different users. Below is a list of the 10 most rated movies.

```{r most rated movies, echo = FALSE, message = FALSE, fig.pos = "placeHere"}
tab <- edx %>% group_by(title) %>% summarize(n = n()) %>% arrange(desc(n)) %>%
  top_n(10)
if(knitr::is_html_output()){
  knitr::kable(tab, "html", caption = "10 Most Rated Movies") %>%
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(tab, "latex", booktabs = TRUE, caption = "10 Most Rated Movies") %>%
    kableExtra::kable_styling(font_size = 8, latex_options = "HOLD_position")
}
```

The distributions below show how often movies are rated and how many ratings a user provides, respectively.  Most movies have less than 1,000 reviews and most users review less than 100 movies.

```{r movie and user histograms, echo = FALSE, message = FALSE, fig.pos='H', fig.cap=   "Distribution of Movie and User Ratings"}
plot1 <- edx %>% 
  count(movieId) %>% 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() + 
  ggtitle("Movies") + 
  xlab("Number of Ratings") +
  ylab("Number of Movies") #most movies have less than 1k reviews

plot2 <- edx %>%
  count(userId) %>% 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() +
  ggtitle("Users") +
  xlab("Number of Ratings") +
  ylab("Number of Users") #most users review less than 100 movies

gridExtra::grid.arrange(plot1, plot2, ncol = 2)
```

Looking at the distribution of average moving rating by user shows that some users don't like many movies and others really tend to enjoy all movies.

```{r user average ratings, echo = FALSE, message = FALSE, warning = FALSE, fig.cap=   "Average Movie Rating by User"}
edx %>% 
  group_by(userId) %>% 
  summarize(b_u = mean(rating)) %>% 
  filter(n()>=100) %>%
  ggplot(aes(b_u)) + 
  geom_histogram(bins = 30, color = "black") + 
  ggtitle("Average Rating by User") +
  xlab ("Average Rating by User") +
  ylab ("Count")#some love everything and some hate everything.
```

Here is a look at the distribution of movie ratings. A rating of 4 is the most common while half point ratings (e.g. 3.5) are much less common than whole point ratings.

```{r ratings distrib, echo = FALSE, message = FALSE, fig.cap=   "Distribution of Movie Ratings"}
qplot(edx$rating, data = edx, bins = 10, color = I("black"),  main = "Movie Rating Distribution", xlab = "Movie Rating", ylab = "Movie Rating Count") #4 is the most common rating
tab <- edx %>% group_by(rating) %>% summarize(count = n()) %>% arrange(desc(count)) #4 is most common

if(knitr::is_html_output()){
  knitr::kable(tab, "html", caption = "Movie Ratings") %>%
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(tab, "latex", booktabs = TRUE, caption = "Movie Ratings") %>%
    kableExtra::kable_styling(font_size = 8, latex_options = "HOLD_position")
}
```

Looking at the number of movie ratings by title shows that the movies with the most ratings are typically blockbusters or action movies.

```{r top 10 most rated, echo = FALSE, message = FALSE}
#number of ratings by movie
tab <- edx %>% group_by(title) %>% summarize(n = n()) %>% arrange(desc(n)) %>%
  top_n(10)
if(knitr::is_html_output()){
  knitr::kable(tab, "html", caption = "10 Most Rated Movies") %>%
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(tab, "latex", booktabs = TRUE, caption = "10 Most Rated Movies") %>%
    kableExtra::kable_styling(font_size = 8, latex_options = "HOLD_position")
}
#the top 10 seem to be mostly blockbusters/action 
```

Movies with the highest average moving rating are typically small, independent movies with fewer total ratings.

```{r top 10 highest rated, echo = FALSE, message = FALSE}
#highest ratings
tab <- edx %>% group_by(title) %>% summarize (n = n(), avg_rating = mean(rating)) %>% arrange(desc(avg_rating)) %>% top_n(10)

if(knitr::is_html_output()){
  knitr::kable(tab, "html", caption = "10 Highest Rated Movies") %>%
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(tab, "latex", booktabs = TRUE, caption = "10 Highest Rated Movies") %>%
    kableExtra::kable_styling(font_size = 8, latex_options = "HOLD_position")
}
#the top ratings appear to be small, independent films with very few ratings

```

Our own intuition tells us that the age of a movie as well as the genre could have an impact on its rating. To look at specific genres we first need to separate out each genre listed for each movie.

```{r split edx by genre, message = FALSE}
edx_genres <- edx %>% separate_rows(genres, sep = "\\|")

```


Then we can look at the average rating by genre. Clearly the Film-Noir genre has a higher avg rating than all other genres.

```{r plot ratings by genre, echo = FALSE, message = FALSE, fig.cap=   "Average Movie Rating by Genre"}
edx_genres %>% group_by(genres) %>% 
  summarize(n = n(), avg = mean(rating), se = sd(rating)/sqrt(n())) %>%
  filter(n >= 1000) %>% 
  mutate(genres = reorder(genres, avg)) %>%
  ggplot(aes(x = genres, y = avg, ymin = avg - 2*se, ymax = avg + 2*se)) + 
  geom_point() +
  geom_errorbar() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  ggtitle("Average Rating by Genre") +
  xlab("Genre") +
  ylab("Average Rating")
```

Based on intuition, Film-Noir doesn't seem to be a popular genre so let's take a look at how many times each genre is rated. There are over 30 times more Drama ratings than Film-Noir ratings.

```{r total ratings by genre, echo = FALSE, message = FALSE}
tab <- edx_genres %>% group_by(genres) %>% 
  summarize(n = n()) %>% filter(n >= 1000) %>% arrange(desc(n))

if(knitr::is_html_output()){
  knitr::kable(tab, "html", caption = "Number of Ratings by Genre") %>%
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(tab, "latex", booktabs = TRUE, caption = "Number of Ratings by Genre") %>%
    kableExtra::kable_styling(font_size = 8, latex_options = "HOLD_position")
}
```

The age of a movie can have an impact on the rating. Contemporary society views change
and older movies can reflect views of different generations.  Let's see if
release year has an effect on ratings. To do this we need to pull the year the movie was released from the movie title.

```{r pull release year from title,  message = FALSE }
library(stringr)
edx <- edx %>% mutate(release_year = as.numeric(str_extract_all(title,
              "(?<=\\()\\d{4}(?=\\))")))
```
\

Then we can look at the average movie ratings by movie release year. This shows that how old a movie is having an effect on the rating.

```{r plot avg rating by release year, echo = FALSE, message = FALSE, fig.cap=   "Average Movie Rating by Release Year"}
edx %>% group_by(release_year) %>%
  summarize(avg_rating = mean(rating)) %>%
  ggplot(aes(release_year, avg_rating)) + geom_point() + geom_smooth() +
  ggtitle("Average Rating vs. Movie Release Year") + xlab("Movie Release Year") +
  ylab("Average Rating")
```
\

Taking four of the more common genres (Action, Comedy, Drama, Romance) and plotting average rating by release year shows genre popularity over time as well.

```{r genre vs release year, echo = FALSE, message = FALSE, warning=FALSE, fig.cap=   "Average Movie Rating by Genre and Release Year"}
edx_genres <- edx_genres %>% 
  mutate(release_year = as.numeric(str_extract_all(title, "(?<=\\()\\d{4}(?=\\))")))
edx_genres %>% 
  filter(genres == c("Action", "Comedy", "Drama", "Romance")) %>%
  group_by(release_year, genres) %>%
  summarize(avg_rating = mean(rating), count = n()) %>%
  ggplot(aes(release_year, avg_rating, col = genres)) + geom_smooth() +
  ggtitle("Average Movie Rating Over Time by Genre") + xlab("Release Year") +
  ylab("Average Rating")
```
\

# Model Development Methods

The performance of the recommendation system will be judged on the residual mean squared error (RMSE) on a validation set. RMSE is defined as^1^:

$$
\mbox{RMSE} = \sqrt{\frac{1}{N} \sum_{u,i}^{} \left( \hat{y}_{u,i} - y_{u,i} \right)^2 }
$$

Where $y_{u,i}$ is the rating for movie $i$ by user $u$, the prediction is $\hat{y}_{u,i}$, $N$ is the number of user/movie combinations with the sum occurring over all combinations.

```{r RMSE function defined, message = FALSE}
#define the RMSE function for testing losses
RMSE <- function(actual_ratings, pred_ratings){
  sqrt(mean((actual_ratings - pred_ratings)^2))
}
```

Since the validation set will only be used once to test our final model we'll need to partition the edx dataset into train and test sets.  A standard partition of 80% for training and 20% for testing was selected since the edx set is still large after the validation split.

```{r create edx test and train sets, echo = FALSE, message = FALSE, warning = FALSE}
#first we need to divide the edx set in to train/test sets.  Giving 20% to test
edx_test_index <- createDataPartition(y = edx$rating, times = 1, p = 0.2, 
                                  list = FALSE)
edx_train_set <- edx[-edx_test_index,]
edx_test_set <- edx[edx_test_index,]

#To make sure we donâ€™t include users and movies in the test set that do 
#not appear in the training set, we remove these entries using the semi_join function:
edx_test_set <- edx_test_set %>% 
  semi_join(edx_train_set, by = "movieId") %>%
  semi_join(edx_train_set, by = "userId")

#making genre/yr version of the test/train sets for later on
edx_train_genres <- edx_train_set %>% separate_rows(genres, sep = "\\|")
edx_train_genres <- edx_train_genres %>% 
  mutate(release_year = as.numeric(str_extract_all(title, "(?<=\\()\\d{4}(?=\\))")))
edx_test_genres <- edx_test_set %>% separate_rows(genres, sep = "\\|")
edx_test_genres <- edx_test_genres %>%
  mutate(release_year = as.numeric(str_extract_all(title, "(?<=\\()\\d{4}(?=\\))")))

```

## Average Rating Model

A simple, initial model to make movie recommendations is to use the average movie rating as the basis for the recommendation. In other words, assume the same rating for all movies.  The linear model would look like this^1^:

$$
Y_{u,i} = \mu + \varepsilon_{u,i}
$$
where $\varepsilon_{i,u}$ is independent errors sampled from the same distribution and $\mu$ is the average rating for all movies. The average rating is 3.512 with an RMSE of 1.06.

```{r mu and mean RMSE, echo = FALSE, message = FALSE}
#start simple with predicting based off the mean movie rating. Y = mu + eps
mean_rating <- mean(edx_train_set$rating) #mu

rmse_mean_rating <- RMSE(edx_test_set$rating, mean_rating) # determine RMSE
#create RMSE table to show model progression
rmse_results <- tibble(Method = "Average Only Model", RMSE = rmse_mean_rating)

#make table
if(knitr::is_html_output()){
  knitr::kable(rmse_results, "html", caption = "RMSE Results") %>%
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(rmse_results, "latex", booktabs = TRUE, caption = "RMSE Results") %>%
    kableExtra::kable_styling(font_size = 8, latex_options = "HOLD_position")
}
```


The standard deviation of the movie ratings is `r sd(edx_train_set$rating)` which nearly matches the RMSE so this is not a good method for making predictions but it can be built on by accounting for effects that were apparent from data exploration.

## Movie Effects

Data exploration showed that different movies tend to get different ratings (e.g. blockbusters vs. independent films).  The movie effect, or the average rating for each movie, is represented as $b_i$ and can be added to the linear model^1^:

$$
Y_{u,i} = \mu + b_i + \varepsilon_{u,i}
$$
The least squares estimate can be used to calculate this effect.  However, in this case, the least squares estimate of $b_i$ is also the average of the difference between the rating of each movie and the overall average rating: 

```{r calculate b_i, message = FALSE, warning= FALSE}
movie_avgs <- edx_train_set %>% 
  group_by(movieId) %>% 
  summarize(b_i = mean(rating - mean_rating)) #calculate the LSE b_i
```

The distribution shows that $b_i$ estimates have quite a bit of variation.

```{r movie effect distrib, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Distrbution of Movie Effect Estimates"}
qplot(b_i, data = movie_avgs, bins = 10, color = I("black"), main = "Distribution of Movie Effect (b_i)", xlab = "Movie Effect (b_i)", ylab = "Movie Effect Count") #showing the variation of b_i
#-3 b_i means a 0.5 star rating because the mean is 3.5 stars
```

Plugging in the $b_i$ estimates into the prediction yields a better RMSE:

```{r RMSE of mean plus movie effect, echo = FALSE, message = FALSE, warning = FALSE}
#make new prediction with the movie effect
pred_movie_eff <- mean_rating + edx_test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  pull(b_i) #add a b_i column to the test set that's organized by movieId
rmse_mov_only <- RMSE(pred_movie_eff, edx_test_set$rating) #improved RMSE of 0.9428

rmse_results <- bind_rows(rmse_results,
                          tibble(Method="Movie Effect Model",
                                     RMSE = rmse_mov_only))

if(knitr::is_html_output()){
  knitr::kable(rmse_results, "html", caption = "RMSE Results") %>%
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(rmse_results, "latex", booktabs = TRUE, caption = "RMSE Results") %>%
    kableExtra::kable_styling(font_size = 8, latex_options = "HOLD_position")
}

```

With just the movie effect the model has improved quite a bit.  This can still be improved by adding more effects.

## User Effects

Data exploration showed that different users tend to rate movies differently (e.g. some love every movie and some don't like any movies).  The user effect, or the average rating for each user, is represented as $b_u$ and can be added to the linear model^1^:

$$
Y_{u,i} = \mu + b_i + b_u + \varepsilon_{u,i}
$$
Similar to the movie effect ($b_i$) the least squares estimate of $b_u$ is also the average of the difference between the rating of each movie, the movie effect, and the overall average rating: 

```{r user effect, message = FALSE, warning = FALSE}
#b_u calculated similarly to b_i
user_avgs <- edx_train_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mean_rating - b_i))

```

Here is the new RMSE with the user effect added:

```{r RMSE movie and user, echo = FALSE, message = FALSE, warning = FALSE}
#make new prediction with the user effect added
pred_user_eff <- edx_test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  mutate(pred = mean_rating + b_i + b_u) %>%
  pull(pred)
rmse_mov_user <- RMSE(pred_user_eff, edx_test_set$rating) #improved RMSE of 0.8655

rmse_results <- bind_rows(rmse_results,
                          data_frame(Method="Movie + User Effect Model",
                                     RMSE = rmse_mov_user ))
if(knitr::is_html_output()){
  knitr::kable(rmse_results, "html", caption = "RMSE Results") %>%
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(rmse_results, "latex", booktabs = TRUE, caption = "RMSE Results") %>%
    kableExtra::kable_styling(font_size = 8, latex_options = "HOLD_position")
}

```

## Release Year Effect

Data exploration showed that the release year appeared to have an effect on movie ratings (e.g. more recent movies had a lower rating on average than movies from the 20th century).  The release year effect, or the average rating for each release year, is represented as $b_y$ and can be added to the linear model:

$$
Y_{u,i} = \mu + b_i + b_u + b_y + \varepsilon_{u,i}
$$
The least squares estimate of $b_y$ can be determined in the same manner that the movie and user effects were calculated:

```{r release year averages, message = FALSE, warning = FALSE}
#b_y calculated similarly to b_i
rel_year_avgs <- edx_train_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by = 'userId') %>%
  group_by(release_year) %>%
  summarize(b_y = mean(rating - mean_rating - b_i - b_u))
```

Here is the newest, slightly improved, RMSE:

```{r RMSE movie, user, release year, echo = FALSE, message = FALSE, warning = FALSE}
pred_rel_year_eff <- edx_test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  left_join(rel_year_avgs, by = 'release_year') %>%
  mutate(pred = mean_rating + b_i + b_u + b_y) %>%
  pull(pred) 
rmse_mov_user_yr <- RMSE(pred_rel_year_eff, edx_test_set$rating) #improved RMSE of 0.8655

rmse_results <- bind_rows(rmse_results,
                          data_frame(Method="Movie + User + Year Effect Model",
                                     RMSE = rmse_mov_user_yr ))
if(knitr::is_html_output()){
  knitr::kable(rmse_results, "html", caption = "RMSE Results") %>%
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(rmse_results, "latex", booktabs = TRUE, caption = "RMSE Results") %>%
    kableExtra::kable_styling(font_size = 8, latex_options = "HOLD_position")
}
```

## Genre Effect

Finally, movie genre also appeared to have an effect on movie ratings.  The genre effect, or the average rating for each genre, is represented as $b_g$ and can be added to the linear model:


$$
Y_{u,i} = \mu + b_i + b_u + b_y + b_g + \varepsilon_{u,i}
$$
 
Recall that each movie can list multiple genres so each listed genre is separated out for each movie. By doing this genre effect becomes the sum of the effects of each genre listed for each movie.  The least squares estimate of $b_g$ is calculated similarly to all the previously discussed effects:

```{r genre effect, message = FALSE, warning = FALSE}
#b_g calculated similarly to b_i
genre_avgs <- edx_train_genres %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by = 'userId') %>%
  left_join(rel_year_avgs, by = "release_year") %>%
  group_by(genres) %>%
  summarize(b_g = mean(rating - mean_rating - b_i - b_u - b_y))
```


Using $b_g$ to make new predictions the newest RMSE is:

```{r RMSE movie, user, release year, genre, echo = FALSE, message = FALSE, warning= FALSE}
pred_genre_eff <- edx_test_genres %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  left_join(rel_year_avgs, by = 'release_year') %>%
  left_join(genre_avgs, by = "genres") %>%
  mutate(pred = mean_rating + b_i + b_u + b_y + b_g) %>%
  pull(pred) 
rmse_mov_user_yr_gen <- RMSE(pred_genre_eff, edx_test_genres$rating) #improved RMSE of 0.8640

rmse_results <- bind_rows(rmse_results,
                          data_frame(Method="Movie + User + Year + Genre Effect Model",
                                     RMSE = rmse_mov_user_yr_gen ))
if(knitr::is_html_output()){
  knitr::kable(rmse_results, "html", caption = "RMSE Results") %>%
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(rmse_results, "latex", booktabs = TRUE, caption = "RMSE Results") %>%
    kableExtra::kable_styling(font_size = 8, latex_options = "HOLD_position")
}
```
\

It seems that the release year effect and the genre effect didn't have as great an impact on the RMSE as the movie and user effects.  

## Regularization

The recommendation model has improved dramatically over the initial method of assuming the average rating for all movies.  However, there may still be room for improvement. Let's take a look at how each effect was wrong.  One way to look at this is the residuals for each effect. The residual is the difference between the actual rating and the estimate. Calculating the movie effect ($b_i$) residuals and looking at the largest 10:

```{r movie effect residuals, echo = FALSE, message= FALSE, warning = FALSE}
tab <- edx_train_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  mutate(resid = rating - (mean_rating + b_i)) %>%
  arrange(desc(abs(resid))) %>% 
  select(title, resid) %>%
  distinct() %>%
  slice(1:10) 
  

if(knitr::is_html_output()){
  knitr::kable(tab, "html", caption = "Highest Movie Effect Residuals") %>%
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(tab, "latex", booktabs = TRUE, caption = "Highest Movie Effect Residuals") %>%
    kableExtra::kable_styling(font_size = 8, latex_options = "HOLD_position")
}
```


Some of these movies are pretty unfamiliar and are way off. Looking closer at $b_i$ here are the top 10 best and worst movies based on the movie effect:

```{r 10 best-worst movie effects,echo=FALSE, message = FALSE, warning=FALSE}
movie_titles <- edx_train_set %>% 
  select(movieId, title) %>%
  distinct() #pull only the uniqe movies (no repeats)

tab1 <- edx_train_set %>% count(movieId) %>% 
  left_join(movie_avgs, by="movieId") %>%
  left_join(movie_titles, by="movieId") %>%
  arrange(desc(b_i)) %>% 
  slice(1:10) %>% 
  select(title, n)

if(knitr::is_html_output()){
  knitr::kable(tab1, "html", caption = "10 Highest Movie Effects", col.names = c("Title", "Number of Ratings")) %>%
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(tab1, "latex", booktabs = TRUE, caption = "10 Highest Movie Effects", col.names = c("Title", "Number of Ratings")) %>%
    kableExtra::kable_styling(font_size = 8, latex_options = "HOLD_position")
}

tab2 <- edx_train_set %>% count(movieId) %>% 
  left_join(movie_avgs, by = "movieId") %>%
  left_join(movie_titles, by="movieId") %>%
  arrange(b_i) %>% 
  slice(1:10) %>% 
  select(title, n)

if(knitr::is_html_output()){
  knitr::kable(tab2, "html", caption = "10 Lowest Movie Effects", col.names = c("Title",           "Number of Ratings")) %>%
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(tab2, "latex", booktabs = TRUE, caption = "10 Lowest Movie Effects", col.names     = c("Title", "Number of Ratings")) %>%
    kableExtra::kable_styling(font_size = 8, latex_options = "HOLD_position")
}
```

In both tables these movies are again pretty unknown.  When you look at the number of times each movie was rated you can see it's very few.  Fewer ratings can lead to greater uncertainty and increase the RMSE.        

Repeating the process but looking at user effect ($b_u$) shows a similar relationship between the number of ratings and the user effect.

```{r highest/lowest 10 user effects, echo=FALSE, message=FALSE, warning=FALSE}
#let's repeat this process for users
users_uniq <- edx_train_set %>% 
  select(userId) %>%
  distinct()
#look at top 10 best and worst user effects
tab1 <- edx_train_set %>% count(userId) %>%
  left_join(user_avgs, by = "userId") %>%
  left_join(users_uniq, by="userId") %>%
  arrange(desc(b_u)) %>% 
  slice(1:10)  %>% 
  select(userId, n)

#make table
if(knitr::is_html_output()){
  knitr::kable(tab1, "html", caption = "10 Highest User Effects", col.names = c("UserId","Number of Ratings")) %>%
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(tab1, "latex", booktabs = TRUE, caption = "10 Highest User Effects", col.names = c("UserId","Number of Ratings")) %>%
    kableExtra::kable_styling(font_size = 8, latex_options = "HOLD_position")
}

tab2 <- edx_train_set %>% count(userId) %>%
  left_join(user_avgs, by = "userId") %>%
  left_join(users_uniq, by="userId") %>%
  arrange(b_u) %>% 
  slice(1:10)  %>% 
  select(userId, n)

#make table
if(knitr::is_html_output()){
  knitr::kable(tab2, "html", caption = "10 Lowest User Effects", col.names = c("UserId","Number of Ratings")) %>%
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(tab2, "latex", booktabs = TRUE, caption = "10 Lowest User Effects", col.names = c("UserId","Number of Ratings")) %>%
    kableExtra::kable_styling(font_size = 8, latex_options = "HOLD_position")
}

```

We already know from intuition that number of movies released per year has increased significantly over time. Also, the analysis of each genre showed Film-Noir had the highest average rating but was also a relatively uncommon genre. Based on these findings, regularization, which penalizes large estimates formed by small sample sizes, could provide some additional benefit in the model. Each effect is then estimated by minimizing the least squares estimate with an additional penalty term ($\lambda$) added. For example, the movie effect ($b_i$) estimate becomes^1^:

$$
\hat{b}_i(\lambda) = \frac{1}{\lambda + n_i} \sum_{u=1}^{n_i} \left(Y_{u,i} - \hat{\mu}\right)
$$
where $n_i$ is the number of ratings for movie $i$. The effect of this equation is to reduce the estimate of $b_i$ when the number of ratings is small but, when $n_i$ is large, $\lambda$ is essentially ignored and the equation becomes an average.  Lambda can be optimized for the lowest RMSE.  The chart below shows RMSE over a range of $\lambda$ values. 

```{r optimizing lambda, echo = FALSE, message = FALSE, warning = FALSE, fig.cap=   "Lambda Effect on RMSE"}
#regularizing and optimizing lambda each effect
lambdas <- seq(1, 7, 0.25)
rmses <- sapply(lambdas, function(l){
  b_i <- edx_train_set %>%
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mean_rating)/(n()+l))
  b_u <- edx_train_set %>% 
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mean_rating)/(n()+l))
  b_y <- edx_train_set %>%
    left_join(b_i, by='movieId') %>%
    left_join(b_u, by='userId') %>%
    group_by(release_year) %>%
    summarize(b_y = sum(rating - mean_rating - b_i - b_u)/(n()+l))
  b_g <- edx_train_genres %>% 
    left_join(b_i, by='movieId') %>%
    left_join(b_u, by='userId') %>%
    left_join(b_y, by = 'release_year') %>%
    group_by(genres) %>%
    summarize(b_g = sum(rating - b_i - b_u - b_y - mean_rating)/(n()+l))
  predicted_ratings <- 
    edx_test_genres %>% 
    left_join(b_i, by='movieId') %>%
    left_join(b_u, by='userId') %>%
    left_join(b_y, by = 'release_year') %>%
    left_join(b_g, by = "genres") %>%
    mutate(pred = mean_rating + b_i + b_u + b_y + b_g) %>%
    pull(pred)
  return(RMSE(predicted_ratings, edx_test_genres$rating))
})

qplot(lambdas, rmses, main = "Lambda Optimization by RMSE", xlab = "Lambda", ylab = "RMSE") #plotting lambda/RMSE results
lambda <- lambdas[which.min(rmses)]
```
\

From the chart we can see that the optimized lambda is `r lambda`.  Comparing the regularized RMSE to the previous models shows that we have improved the model even further.

```{r final RMSE table, message = FALSE, echo = FALSE, warning = FALSE}
#running regularized prediction with optimized lambda
movie_reg_avgs <- edx_train_set %>% 
  group_by(movieId) %>% 
  summarize(b_i = sum(rating - mean_rating)/(n()+lambda), n_i = n()) 
user_reg_avgs <- edx_train_set %>%  
  left_join(movie_reg_avgs, by = 'movieId') %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - mean_rating - b_i)/(n()+lambda), n_u = n())
rel_year_reg_avgs <- edx_train_set %>% 
  left_join(movie_reg_avgs, by='movieId') %>%
  left_join(user_reg_avgs, by = 'userId') %>%
  group_by(release_year) %>%
  summarize(b_y = sum(rating - mean_rating - b_i - b_u)/(n()+lambda), n_y = n())
genre_reg_avgs <- edx_train_genres %>% 
  left_join(movie_reg_avgs, by='movieId') %>%
  left_join(user_reg_avgs, by = 'userId') %>%
  left_join(rel_year_reg_avgs, by = "release_year") %>%
  group_by(genres) %>%
  summarize(b_g = sum(rating - mean_rating - b_i - b_u - b_y)/(n()+lambda), n_g = n())
predicted_full_reg_ratings <- edx_test_genres %>% 
  left_join(movie_reg_avgs, by='movieId') %>%
  left_join(user_reg_avgs, by = 'userId') %>%
  left_join(rel_year_reg_avgs, by = "release_year") %>%
  left_join(genre_reg_avgs, by = 'genres') %>%
  mutate(pred = mean_rating + b_i + b_u + b_y + b_g) %>%
  pull(pred)
rmse_full_reg <- RMSE(predicted_full_reg_ratings, edx_test_genres$rating)
rmse_results <- bind_rows(rmse_results,
                          data_frame(Method="Regularized Movie + User + Year + Genre Effect Model",  
                                     RMSE = rmse_full_reg))
#make table
if(knitr::is_html_output()){
  knitr::kable(rmse_results, "html", caption = "RMSE Results") %>%
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(rmse_results, "latex", booktabs = TRUE, caption = "RMSE Results") %>%
    kableExtra::kable_styling(font_size = 8, latex_options = "HOLD_position")
}
```
\

# Results

As a final step, recalculate each regularized effect on the entire edx set using the optimized lambda from the training set.  Then use the model to make predictions on the validation set created initially and so far unused for training or testing. In order to use genre and release year, the validation set is separated by genre and a release year column is added in the same manner that the edx data set was modified. Finally the RMSE of the predictions on the validation set is calculated.

```{r RMSE on validation set, echo = FALSE, message = FALSE, warning = FALSE}
#using the entire edx set
#calculate each using the optimized lambda from the training set.
b_i <- edx %>%
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mean_rating)/(n()+lambda))
b_u <- edx %>% 
  left_join(b_i, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - mean_rating)/(n()+lambda))
b_y <- edx %>% 
  left_join(b_i, by="movieId") %>%
  left_join(b_u, by="userId") %>%
  group_by(release_year) %>%
  summarize(b_y = sum(rating - b_i - b_u - mean_rating)/(n()+lambda))
b_g <- edx_genres %>% 
  left_join(b_i, by="movieId") %>%
  left_join(b_u, by="userId") %>%
  left_join(b_y, by = "release_year") %>%
  group_by(genres) %>%
  summarize(b_g = sum(rating - b_i - b_u - b_y - mean_rating)/(n()+lambda))

#split the validation set into genres
validation_genres <- validation %>% separate_rows(genres, sep = "\\|")
validation_genres <- validation_genres %>% 
  mutate(release_year = as.numeric(str_extract_all(title, "(?<=\\()\\d{4}(?=\\))"))) 
  
#make predictions on the validation set
pred_val_set <- validation_genres %>%
  left_join(b_i, by = 'movieId') %>%
  left_join(b_u, by = 'userId') %>%
  left_join(b_y, by = 'release_year') %>%
  left_join(b_g, by = 'genres') %>%
  mutate(predic = mean_rating + b_i + b_u + b_y + b_g) %>%
  pull(predic)
#calculate the RMSE on the validation set
final_RMSE <- RMSE(pred_val_set, validation_genres$rating)
rmse_validation <- tibble(Method = "Regularized Movie + User + Year + Genre Effect Model", RMSE = final_RMSE)
#make table
if(knitr::is_html_output()){
  knitr::kable(rmse_validation, "html", caption = "Validation RMSE") %>%
    kableExtra::kable_styling(bootstrap_options = "striped", full_width = FALSE)
} else{
  knitr::kable(rmse_validation, "latex", booktabs = TRUE, caption = "Validation RMSE") %>%
    kableExtra::kable_styling(font_size = 8, latex_options = "HOLD_position")
}
```
\

# Conclusion

Data analysis and visualization showed the effects that the movie, user, genre, and age of the movie have on the rating.  A linear regression model was created to account for each of these effects.  The residual mean squared error (RMSE) was used to validate the model with a final RMSE of 0.8623. One modeling method that could further improve the prediction model could be exploring any effect that the timestamp of the movie rating had on the rating. Another would be to look into to breaking down release year effect by genre.  Singular value decomposition and principal component analysis could potentially derive underlying rating effects that aren't initially obvious from the data visualization performed here.


## References

1) Irizarry, Rafael A. [_Introduction to Data Science: Data Analysis and Prediction   Algorithms with R_](https://rafalab.github.io/dsbook/). 2020.
